# System Architecture

## Design Philosophy: Focused Analyzers

> **Core Principle: Analyzers work best when they don't have too many jobs.**

This is the foundational principle behind the pipeline architecture. Each analyzer does ONE focused thing well. When a task can be split into independent work, split it and run in parallel.

### Why This Matters

AI analyzers produce better results when they have a clear, focused task. A single prompt asking an AI to "generate Instagram, Twitter, LinkedIn, AND Facebook content" produces worse results than four specialized prompts.

### Stage 8: The Case Study

Stage 8 (Social Content) demonstrates this philosophy:

```
WRONG (avoided):                    RIGHT (implemented):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ generateSocial()    â”‚             â”‚ generateInstagram() â”‚ â† focused
â”‚ â€¢ Instagram logic   â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â€¢ Twitter logic     â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ LinkedIn logic    â”‚     â”€â”€â”€â–º    â”‚ generateTwitter()   â”‚ â† focused
â”‚ â€¢ Facebook logic    â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ (400+ lines)        â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚ generateLinkedIn()  â”‚ â† focused
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ generateFacebook()  â”‚ â† focused
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    (All 4 run in PARALLEL)
```

**Benefits:**
- Better quality (specialized prompts per platform)
- ~30% faster (parallel execution)
- Easier to test (isolated modules)
- Clearer code (single responsibility)

### Canonical Data Sources

No duplicate work across stages:

| Data | Canonical Source | Rule |
|------|------------------|------|
| Episode Summary | Stage 1 `episode_crux` | Only Stage 1 creates the summary |
| Verbatim Quotes | Stage 2 `quotes[]` | Only Stage 2 extracts quotes |

> **See [PIPELINE-REFERENCE.md](./PIPELINE-REFERENCE.md) for complete pipeline documentation.**

---

## Architectural Principles

### Modularity Requirements

**CRITICAL: Every file must have a single, clear responsibility and should not exceed 400 lines of code.**

When a file approaches 400 lines:
1. Identify distinct responsibilities
2. Extract into separate modules
3. Use clear interfaces between modules
4. Document why the split was made

### Code Organization

```
backend/
â”œâ”€â”€ analyzers/                    # AI analysis modules (one per stage, 0-9)
â”‚   â”œâ”€â”€ stage-00-preprocess-transcript.js    (~300 lines - Claude Haiku)
â”‚   â”œâ”€â”€ stage-01-analyze-transcript.js       (~300 lines)
â”‚   â”œâ”€â”€ stage-02-extract-quotes.js           (~300 lines)
â”‚   â”œâ”€â”€ stage-03-outline-high-level.js       (~300 lines)
â”‚   â”œâ”€â”€ stage-04-outline-paragraphs.js       (~300 lines)
â”‚   â”œâ”€â”€ stage-05-generate-headlines.js       (~300 lines)
â”‚   â”œâ”€â”€ stage-06-draft-blog-post.js          (~350 lines - two API calls)
â”‚   â”œâ”€â”€ stage-07-refine-with-claude.js       (~300 lines)
â”‚   â”œâ”€â”€ stage-08-social-platform.js          (~255 lines - 4 platform exports)
â”‚   â””â”€â”€ stage-09-generate-email.js           (~300 lines)
â”‚
â”œâ”€â”€ parsers/                      # Response validators (one per stage)
â”‚   â”œâ”€â”€ parse-episode-analysis.js            (~200 lines)
â”‚   â”œâ”€â”€ parse-quotes.js                      (~200 lines)
â”‚   â”œâ”€â”€ parse-blog-outline.js                (~200 lines)
â”‚   â”œâ”€â”€ parse-paragraph-outlines.js          (~200 lines)
â”‚   â”œâ”€â”€ parse-headlines.js                   (~150 lines)
â”‚   â”œâ”€â”€ parse-blog-draft.js                  (~150 lines)
â”‚   â”œâ”€â”€ parse-refined-post.js                (~150 lines)
â”‚   â”œâ”€â”€ parse-social-content.js              (~250 lines)
â”‚   â””â”€â”€ parse-email-campaign.js              (~200 lines)
â”‚
â”œâ”€â”€ lib/                          # Shared utilities
â”‚   â”œâ”€â”€ api-client-openai.js                 (~300 lines)
â”‚   â”œâ”€â”€ api-client-anthropic.js              (~300 lines)
â”‚   â”œâ”€â”€ cost-calculator.js                   (~250 lines)
â”‚   â”œâ”€â”€ logger.js                            (~200 lines)
â”‚   â”œâ”€â”€ prompt-loader.js                     (~200 lines)
â”‚   â”œâ”€â”€ supabase-client.js                   (~300 lines)
â”‚   â”œâ”€â”€ retry-logic.js                       (~200 lines)
â”‚   â””â”€â”€ validators.js                        (~200 lines)
â”‚
â”œâ”€â”€ api/                          # Express routes
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ episodes.js                      (~350 lines)
â”‚   â”‚   â”œâ”€â”€ stages.js                        (~250 lines)
â”‚   â”‚   â”œâ”€â”€ evergreen.js                     (~200 lines)
â”‚   â”‚   â”œâ”€â”€ library.js                       (~350 lines - content library)
â”‚   â”‚   â”œâ”€â”€ calendar.js                      (~400 lines - content calendar)
â”‚   â”‚   â””â”€â”€ admin.js                         (~300 lines)
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ error-handler.js                 (~150 lines)
â”‚   â”‚   â”œâ”€â”€ logger-middleware.js             (~100 lines)
â”‚   â”‚   â””â”€â”€ validation.js                    (~200 lines)
â”‚   â””â”€â”€ server.js                            (~200 lines)
â”‚
â”œâ”€â”€ prompts/                      # AI prompt templates (markdown)
â”‚   â”œâ”€â”€ stage-01-transcript-analysis.md
â”‚   â”œâ”€â”€ stage-02-quote-extraction.md
â”‚   â”œâ”€â”€ stage-03-blog-outline.md
â”‚   â”œâ”€â”€ stage-04-paragraph-outlines.md
â”‚   â”œâ”€â”€ stage-05-headlines.md
â”‚   â”œâ”€â”€ stage-06-draft-generation.md
â”‚   â”œâ”€â”€ stage-07-refinement.md
â”‚   â”œâ”€â”€ stage-08-social-content.md
â”‚   â”œâ”€â”€ stage-09-email-campaign.md
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ never-use-list.md
â”‚       â””â”€â”€ quality-frameworks.md
â”‚
â”œâ”€â”€ types/                        # TypeScript definitions
â”‚   â”œâ”€â”€ episode.ts                           (~200 lines)
â”‚   â”œâ”€â”€ stage-outputs.ts                     (~300 lines)
â”‚   â”œâ”€â”€ api-responses.ts                     (~200 lines)
â”‚   â””â”€â”€ database.ts                          (~300 lines)
â”‚
â””â”€â”€ orchestrator/                 # Pipeline coordination
    â”œâ”€â”€ episode-processor.js                 (~450 lines - main orchestrator)
    â”œâ”€â”€ stage-runner.js                      (~300 lines - stage execution)
    â”œâ”€â”€ phase-config.js                      (~400 lines - phase definitions)
    â””â”€â”€ phase-executor.js                    (~350 lines - parallel execution)

frontend/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ shared/                   # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ Button.jsx                       (~150 lines)
â”‚   â”‚   â”œâ”€â”€ Input.jsx                        (~150 lines)
â”‚   â”‚   â”œâ”€â”€ Card.jsx                         (~100 lines)
â”‚   â”‚   â”œâ”€â”€ Modal.jsx                        (~200 lines)
â”‚   â”‚   â”œâ”€â”€ Toast.jsx                        (~150 lines)
â”‚   â”‚   â”œâ”€â”€ LoadingSpinner.jsx               (~80 lines)
â”‚   â”‚   â”œâ”€â”€ ProgressBar.jsx                  (~100 lines)
â”‚   â”‚   â”œâ”€â”€ Badge.jsx                        (~80 lines)
â”‚   â”‚   â”œâ”€â”€ ScheduleModal.jsx                (~300 lines - content scheduling)
â”‚   â”‚   â””â”€â”€ SaveToLibraryModal.jsx           (~250 lines - save to library)
â”‚   â”‚
â”‚   â”œâ”€â”€ episode/                  # Episode-specific components
â”‚   â”‚   â”œâ”€â”€ EpisodeCard.jsx                  (~200 lines)
â”‚   â”‚   â”œâ”€â”€ EpisodeList.jsx                  (~250 lines)
â”‚   â”‚   â””â”€â”€ StageIndicator.jsx               (~150 lines)
â”‚   â”‚
â”‚   â””â”€â”€ review/                   # Review hub components
â”‚       â”œâ”€â”€ AnalysisTab.jsx                  (~300 lines)
â”‚       â”œâ”€â”€ OutlineTab.jsx                   (~300 lines)
â”‚       â”œâ”€â”€ BlogPostTab.jsx                  (~400 lines)
â”‚       â”œâ”€â”€ HeadlinesTab.jsx                 (~300 lines)
â”‚       â”œâ”€â”€ SocialTab.jsx                    (~400 lines)
â”‚       â””â”€â”€ EmailTab.jsx                     (~350 lines)
â”‚
â”œâ”€â”€ pages/                        # Page-level components
â”‚   â”œâ”€â”€ Dashboard.jsx                        (~400 lines)
â”‚   â”œâ”€â”€ Settings.jsx                         (~400 lines)
â”‚   â”œâ”€â”€ NewEpisode.jsx                       (~350 lines)
â”‚   â”œâ”€â”€ ProcessingScreen.jsx                 (~400 lines)
â”‚   â”œâ”€â”€ ReviewHub.jsx                        (~400 lines - tab orchestration)
â”‚   â”œâ”€â”€ ContentLibrary.jsx                   (~350 lines - saved content)
â”‚   â”œâ”€â”€ ContentCalendar.jsx                  (~400 lines - publishing schedule)
â”‚   â””â”€â”€ AdminDashboard.jsx                   (~400 lines)
â”‚
â”œâ”€â”€ hooks/                        # Custom React hooks
â”‚   â”œâ”€â”€ useEpisode.js                        (~150 lines)
â”‚   â”œâ”€â”€ useStageUpdates.js                   (~200 lines - real-time)
â”‚   â”œâ”€â”€ useEvergreenContent.js               (~150 lines)
â”‚   â””â”€â”€ useAdminData.js                      (~200 lines)
â”‚
â”œâ”€â”€ styles/                       # Design system
â”‚   â”œâ”€â”€ variables.css                        (~100 lines)
â”‚   â”œâ”€â”€ typography.css                       (~80 lines)
â”‚   â”œâ”€â”€ components.css                       (~200 lines)
â”‚   â””â”€â”€ utilities.css                        (~150 lines)
â”‚
â””â”€â”€ utils/                        # Frontend utilities
    â”œâ”€â”€ api-client.js                        (~200 lines)
    â”œâ”€â”€ formatting.js                        (~150 lines)
    â””â”€â”€ validation.js                        (~150 lines)
```

## Phase-Based Execution Model

The pipeline is organized into **4 phases** with parallel execution where possible:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸšª PRE-GATE: Preprocessing (Conditional)                                  â”‚
â”‚    Stage 0: preprocessTranscript (Claude Haiku)                          â”‚
â”‚    Only runs if transcript > 8000 tokens                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“¤ PHASE 1: EXTRACT (Parallel) âš¡                                         â”‚
â”‚    Stage 1: analyzeTranscript + Stage 2: extractQuotes                   â”‚
â”‚    Both run in PARALLEL - they only need the transcript                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“‹ PHASE 2: PLAN (Grouped)                                                â”‚
â”‚    Stage 3: outline (first, sequential)                                  â”‚
â”‚    Stage 4: paragraphs + Stage 5: headlines (then, PARALLEL) âš¡          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœï¸ PHASE 3: WRITE (Sequential)                                            â”‚
â”‚    Stage 6: draft â†’ Stage 7: refine                                      â”‚
â”‚    Must be sequential - refine needs the draft                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“£ PHASE 4: DISTRIBUTE (5 tasks in PARALLEL) âš¡                           â”‚
â”‚    Stage 8a: Instagram  â”€â”                                               â”‚
â”‚    Stage 8b: Twitter/X   â”‚                                               â”‚
â”‚    Stage 8c: LinkedIn    â”œâ”€ All 5 run PARALLEL (focused analyzer design) â”‚
â”‚    Stage 8d: Facebook    â”‚                                               â”‚
â”‚    Stage 9:  Email      â”€â”˜                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Benefits

| Phase | Tasks | Execution | Time Saved |
|-------|-------|-----------|------------|
| Phase 1 | 2 | Parallel | ~7 sec |
| Phase 2 | 3 | 1 sequential + 2 parallel | ~5 sec |
| Phase 3 | 2 | Sequential | 0 sec |
| Phase 4 | 5 | Parallel (focused analyzers) | ~6 sec |
| **Total** | **12** | | **~18 sec (~30%)** |

### Key Files

| File | Purpose |
|------|---------|
| `phase-config.js` | Phase definitions, task dependencies |
| `phase-executor.js` | Parallel execution, timeout handling |
| `episode-processor.js` | Main orchestrator, phase coordination |
| `stage-runner.js` | Individual stage execution |

### Design Principles

1. **Atomic Phases**: A phase either fully succeeds or fully fails
2. **Phase-Level Retry**: If any task fails, retry the entire phase
3. **Isolated Results**: Parallel tasks write to isolated results, merged after
4. **Fail Fast**: Cancel remaining tasks on first failure

## Stage-to-Model Mapping

Each stage uses the most appropriate AI model for its task:

| Stage | Name | Model | Provider | Phase | Purpose |
|-------|------|-------|----------|-------|---------|
| 0 | Preprocessing | Claude Haiku | Anthropic | pregate | Compress long transcripts (200K context) |
| 1 | Analysis | GPT-5 mini | OpenAI | extract | Extract metadata, themes, `episode_crux` â­ |
| 2 | Quote Extraction | Claude Haiku | Anthropic | extract | Extract verbatim `quotes[]` â­ |
| 3 | Blog Outline | GPT-5 mini | OpenAI | plan | High-level post structure |
| 4 | Paragraph Outlines | GPT-5 mini | OpenAI | plan | Detailed section plans |
| 5 | Headlines | GPT-5 mini | OpenAI | plan | Title and copy options |
| 6 | Draft Generation | GPT-5 mini | OpenAI | write | Write the blog post |
| 7 | Refinement | Claude Sonnet | Anthropic | write | Polish and improve |
| 8a | Instagram | Claude Sonnet | Anthropic | distribute | Instagram-specific posts |
| 8b | Twitter/X | Claude Sonnet | Anthropic | distribute | Twitter-specific posts |
| 8c | LinkedIn | Claude Sonnet | Anthropic | distribute | LinkedIn-specific posts |
| 8d | Facebook | Claude Sonnet | Anthropic | distribute | Facebook-specific posts |
| 9 | Email Campaign | Claude Sonnet | Anthropic | distribute | Newsletter content |

â­ = Canonical data source (all downstream stages reference this)

## Quote Architecture

**IMPORTANT:** Stage 2 is the SOLE source of quotes for the entire pipeline.

### Quote Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ORIGINAL TRANSCRIPT (always used for Stage 2, never the summary)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: Quote Extraction (Claude Haiku)                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ Extracts 8-12 verbatim quotes with standardized structure:          â”‚
â”‚                                                                     â”‚
â”‚ {                                                                   â”‚
â”‚   quotes: [                                                         â”‚
â”‚     {                                                               â”‚
â”‚       text: "Exact verbatim quote...",  // Required                â”‚
â”‚       speaker: "Dr. Jane Smith",         // Required                â”‚
â”‚       context: "Why significant...",     // Optional                â”‚
â”‚       usage: "headline|pullquote|social|key_point" // Optional     â”‚
â”‚     }                                                               â”‚
â”‚   ]                                                                 â”‚
â”‚ }                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 6: Blog     â”‚ â”‚ Stage 8: Social   â”‚ â”‚ Frontend UI       â”‚
â”‚ Draft Generation  â”‚ â”‚ Content           â”‚ â”‚ (ReviewHub)       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ Integrates quotes â”‚ â”‚ Uses quotes for   â”‚ â”‚ Displays quotes   â”‚
â”‚ into blog post    â”‚ â”‚ social media      â”‚ â”‚ with copy button  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Accessing Quotes in Code

**In Analyzers:**
```javascript
const quotes = previousStages[2]?.quotes;
```

**In Prompt Templates:**
```
{{STAGE_2_QUOTES}}
```

### Why Stage 2 Uses Haiku

1. **Extraction Task** - Not creative generation, just finding verbatim text
2. **200K Context** - Handles very long transcripts without truncation
3. **Cost Effective** - Much cheaper than GPT-5 mini for this task
4. **Fast** - Quicker response times for the extraction task
5. **Accuracy** - Excellent at precise, verbatim extraction

### Stage 0 Does NOT Extract Quotes

Stage 0 (preprocessing) focuses ONLY on:
- Compressing long transcripts into summaries
- Identifying speakers and topics
- Extracting episode metadata (title, duration - but NOT a core_message summary)

**Stage 0 does not extract quotes** to maintain single responsibility and avoid diluted output quality.

### No Duplicate Summarization

**IMPORTANT:** The pipeline has one canonical summary: **Stage 1's `episode_crux`**.

| Stage | What it does NOT do | Why |
|-------|---------------------|-----|
| Stage 0 | Does NOT create a `core_message` summary | Stage 1 handles this with `episode_crux` |
| Stage 3 | Does NOT create a `narrative_summary` | Uses `episode_crux` from Stage 1 instead |

This design prevents redundant AI calls doing the same summarization work, saving tokens and money.

## Data Flow Architecture

> **See also:** [STAGE-DATA-FLOW.md](./STAGE-DATA-FLOW.md) for detailed documentation on how data flows between stages, including the `previousStages` object structure and common debugging tips.

### Episode Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend                             â”‚
â”‚  [Upload] â†’ [Start Processing] â†’ [Subscribe to Updates]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Layer                               â”‚
â”‚  POST /api/episodes/:id/process                             â”‚
â”‚  â†’ Validates input                                           â”‚
â”‚  â†’ Creates stage records                                     â”‚
â”‚  â†’ Triggers orchestrator                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Orchestrator                              â”‚
â”‚  episode-processor.js                                        â”‚
â”‚  â†’ Loads context (transcript + evergreen)                    â”‚
â”‚  â†’ For stage 0-9:                                            â”‚
â”‚    â”œâ”€ Stage 0: Preprocess (Claude Haiku, skipped for short)  â”‚
â”‚    â”œâ”€ Update status to "processing"                          â”‚
â”‚    â”œâ”€ Call stage analyzer                                    â”‚
â”‚    â”œâ”€ Parse & validate response                              â”‚
â”‚    â”œâ”€ Save output to database                                â”‚
â”‚    â”œâ”€ Log tokens/cost/duration                               â”‚
â”‚    â””â”€ Update status to "completed"                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚               â”‚
                 â–¼               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    Analyzers      â”‚   â”‚    Parsers        â”‚
     â”‚  (call AI APIs)   â”‚   â”‚  (validate data)  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                       â”‚
               â–¼                       â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   OpenAI API      â”‚   â”‚  Validation       â”‚
     â”‚   Anthropic API   â”‚   â”‚  Type Checking    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Supabase Database   â”‚
               â”‚   - episodes          â”‚
               â”‚   - stage_outputs     â”‚
               â”‚   - api_usage_log     â”‚
               â”‚   - content_library   â”‚
               â”‚   - content_calendar  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼ (Real-time subscription)
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Frontend Update     â”‚
               â”‚   (Stage progress)    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Real-Time Updates Flow

```
1. Backend updates stage_outputs table
   â””â”€> Supabase triggers PostgreSQL NOTIFY

2. Supabase broadcasts change via WebSocket
   â””â”€> Realtime channel: "episode-updates"

3. Frontend receives update
   â””â”€> useStageUpdates hook processes change
   â””â”€> Component state updates
   â””â”€> UI reflects new status
```

## Module Communication Patterns

### Analyzer Module Pattern

Every analyzer module follows this interface:

```javascript
/**
 * Analyzer for Stage X: [Purpose]
 * @param {Object} context - Execution context
 * @param {string} context.episodeId - Episode UUID
 * @param {string} context.transcript - Full transcript
 * @param {Object} context.evergreen - Evergreen settings
 * @param {Object} context.previousStages - Outputs from stages 1 to X-1
 * @returns {Promise<Object>} Structured stage output
 * @throws {APIError} If AI API call fails
 * @throws {ValidationError} If response is invalid
 */
async function analyzeStage(context) {
  // 1. Load prompt template
  const prompt = await loadPrompt('stage-X', context);
  
  // 2. Call AI API
  const response = await callAI(prompt, options);
  
  // 3. Parse response
  const parsed = parseResponse(response);
  
  // 4. Validate structure
  validateStageOutput(parsed);
  
  // 5. Log usage
  logAPIUsage(response.usage, context.episodeId);
  
  // 6. Return structured data
  return parsed;
}
```

**Key Requirements:**
- Each analyzer is 250-350 lines max
- Single responsibility: call AI, parse, validate, return
- No database access (handled by orchestrator)
- No side effects beyond logging
- Comprehensive error handling

**Output Structure (CRITICAL):**

Every analyzer must return both `output_data` and `output_text`, even if one is null:

```javascript
return {
  output_data: { /* structured JSON */ } || null,
  output_text: "markdown content" || null,
  input_tokens: number,
  output_tokens: number,
  cost_usd: number,
};
```

The orchestrator merges BOTH into `previousStages[stageNum]` for downstream access:

```javascript
// Downstream stages can access either:
previousStages[6].word_count     // from output_data
previousStages[6].output_text    // the actual blog post
```

### Parser Module Pattern

Every parser module follows this interface:

```javascript
/**
 * Parser for Stage X output
 * @param {Object} rawResponse - Raw AI API response
 * @returns {Object} Validated structured data
 * @throws {ValidationError} If structure is invalid
 */
function parseStageOutput(rawResponse) {
  // 1. Extract relevant data
  const data = extractData(rawResponse);
  
  // 2. Type checking
  validateTypes(data);
  
  // 3. Business logic validation
  validateBusinessRules(data);
  
  // 4. Return cleaned data
  return data;
}
```

**Key Requirements:**
- Each parser is 150-250 lines max
- No API calls (pure function)
- Throws descriptive errors
- Returns consistent structure

### Utility Module Pattern

Shared utilities provide common functionality:

```javascript
// api-client-openai.js
export async function callOpenAI(prompt, options) {
  // Handles: auth, rate limiting, retries, token counting
}

// cost-calculator.js
export function calculateCost(usage, model) {
  // Returns cost in USD based on token usage
}

// logger.js
export function log(level, message, metadata) {
  // Structured logging to console + database
}

// prompt-loader.js
export async function loadPrompt(stageName, variables) {
  // Loads template, substitutes variables, returns string
}
```

## Error Handling Architecture

### Error Types

```javascript
// lib/errors.js

class APIError extends Error {
  constructor(provider, statusCode, message) {
    super(message);
    this.name = 'APIError';
    this.provider = provider; // 'openai' | 'anthropic'
    this.statusCode = statusCode;
    this.retryable = [429, 500, 502, 503].includes(statusCode);
  }
}

class ValidationError extends Error {
  constructor(field, reason) {
    super(`Validation failed for ${field}: ${reason}`);
    this.name = 'ValidationError';
    this.field = field;
    this.retryable = false;
  }
}

class DatabaseError extends Error {
  constructor(operation, message) {
    super(message);
    this.name = 'DatabaseError';
    this.operation = operation;
    this.retryable = true;
  }
}
```

### Retry Strategy

```javascript
// lib/retry-logic.js

async function retryWithBackoff(fn, options = {}) {
  const {
    maxRetries = 3,
    initialDelay = 1000,
    maxDelay = 10000,
    backoffFactor = 2
  } = options;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      if (!error.retryable || attempt === maxRetries) {
        throw error;
      }
      
      const delay = Math.min(
        initialDelay * Math.pow(backoffFactor, attempt),
        maxDelay
      );
      
      logger.warn('Retrying after error', {
        attempt: attempt + 1,
        delay,
        error: error.message
      });
      
      await sleep(delay);
    }
  }
}
```

## Logging Architecture

### Structured Logging Format

```javascript
{
  "timestamp": "2025-01-13T20:45:32.123Z",
  "level": "INFO",
  "service": "backend",
  "episode_id": "uuid",
  "stage": 3,
  "message": "Stage completed successfully",
  "metadata": {
    "duration_ms": 1234,
    "tokens_input": 1500,
    "tokens_output": 800,
    "cost_usd": 0.0045,
    "model": "gpt-5-mini"
  }
}
```

### Log Levels Usage

- **DEBUG**: Detailed flow (function entry/exit, variable values)
- **INFO**: Key milestones (stage start/complete, API calls)
- **WARN**: Recoverable issues (retries, missing optional data)
- **ERROR**: Failures (API errors, validation failures)

### What to Log

**ALWAYS LOG:**
- Stage start/end with episode_id and stage number
- AI API calls with model, tokens, cost, duration
- Errors with full stack trace and context
- Retry attempts with reason

**NEVER LOG:**
- Full transcripts (too large, PII)
- API keys or secrets
- Unredacted PII

## Database Interaction Patterns

### Repository Pattern

```javascript
// lib/repositories/episode-repository.js

class EpisodeRepository {
  constructor(supabaseClient) {
    this.db = supabaseClient;
  }
  
  async create(data) {
    // CREATE operations
  }
  
  async findById(id) {
    // READ operations
  }
  
  async update(id, data) {
    // UPDATE operations
  }
  
  async delete(id) {
    // DELETE operations
  }
}
```

**Benefits:**
- Centralized database logic
- Easy to mock for testing
- Consistent error handling
- Query optimization in one place

## Frontend State Management

### Context + Hooks Pattern

```javascript
// contexts/EpisodeContext.jsx
const EpisodeContext = createContext();

export function EpisodeProvider({ children }) {
  const [episodes, setEpisodes] = useState([]);
  const [loading, setLoading] = useState(true);
  
  // Subscribe to real-time updates
  useEffect(() => {
    const subscription = supabase
      .channel('episodes')
      .on('postgres_changes', {
        event: '*',
        schema: 'public',
        table: 'episodes'
      }, handleChange)
      .subscribe();
      
    return () => subscription.unsubscribe();
  }, []);
  
  return (
    <EpisodeContext.Provider value={{ episodes, loading }}>
      {children}
    </EpisodeContext.Provider>
  );
}

// Custom hook for consuming context
export function useEpisodes() {
  return useContext(EpisodeContext);
}
```

## Performance Considerations

### Database Indexes

```sql
-- Critical for queries
CREATE INDEX idx_episodes_status ON episodes(status);
CREATE INDEX idx_episodes_created_at ON episodes(created_at DESC);
CREATE INDEX idx_stage_outputs_episode ON stage_outputs(episode_id);
CREATE INDEX idx_stage_outputs_stage ON stage_outputs(stage_number);
CREATE INDEX idx_api_usage_timestamp ON api_usage_log(timestamp DESC);
```

### API Response Optimization

- Use `select` to limit returned fields
- Paginate large lists (episodes, logs)
- Cache evergreen content in memory
- Stream long responses where possible

### Frontend Optimization

- Lazy load tabs in Review Hub
- Virtualize long lists (admin logs)
- Debounce search inputs
- Memoize expensive computations

## Security Considerations

### API Keys

- Store in environment variables, never in code
- Use separate keys for dev/production
- Rotate keys periodically
- Rate limit API endpoints

### Database Security

- Row-level security policies
- Prepared statements (prevent SQL injection)
- Input validation on all endpoints
- Sanitize user input before storing

### Content Security

- No PII in logs
- Secure transcript storage
- User owns all generated content
- Clear data retention policy

---

**This architecture prioritizes modularity, maintainability, and clear separation of concerns. Every module should be independently testable and replaceable.**
